net_name: 'AttUnet'
# train_dir: '/home/jzw/data/LiTS/LITS17/train_image' # '/home/jzw/data/LiTS/fixed_data/'
# train_list: '/home/jzw/workspace_seg/template_jzw/datatxt/LitsSeg_train.txt'
# test_dir: '/home/jzw/data/LiTS/fixed_data/'
# test_list: '/home/jzw/workspace_seg/template_jzw/datatxt/LitsSeg_test.txt'
## depth in CT 
# depth: 24

pretrain_model: '' # /home/xzy/projects/BrainSeg/checkpoints/BrainSeg/Unet3D/epoch_85_model_final.pth
resume_model: '' #'runs/lits_seg/unet/train/2021-09-16-22-20-37/checkpoints/epoch_100_model_best_loss.pth'
input_height: 352
input_width: 352

train_epoch : 100
save_every_epoch : 1
early_stop: 20
# change the batchsize on each GPU
batch_size: 8 # 32 
print_freq : 100
last_iter : -1 
augment: True
sync: True
# train_output_directory: 'checkpoints/LitsSeg/UNet' # checkout save state_dict
# log_directory: 'logs/LitsSeg/UNet' # summery writer
running_root: 'runs/lits_liver_seg/attunet'
# checkpoint_directory: 'checkpoints/LitsSeg/UNet'
# summary_directory: 'summarys/LitsSeg/UNet'
# savedir: 'checkpoints/save'

bn: 'sync'

model:
  in_channels: 1
  out_channels: 1


optimizer:
  type: 'adam'
  
lr_scheduler:
  base_lr: 0.001
  type: STEP                  #or COSINE
  gamma: 0.1                  #default for STEP
  verbose: False               #default for STEP
  step_size: 60              #default for STEP
  last_epoch: -1       

loss:
  type: 'bcel' #'focal' 
  # kwargs:
  #   class_num: 2

thr: 0.55
